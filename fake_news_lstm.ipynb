{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\dagma\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This code is an adaptation of\n",
    "# source: https://www.kaggle.com/code/atishadhikari/fake-news-cleaning-word2vec-lstm-99-accuracy\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "\n",
    "import tensorflow\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preparation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "fake = pd.read_csv(\"./data/Fake.csv\")\n",
    "real = pd.read_csv(\"./data/True.csv\")\n",
    "\n",
    "#fake = pd.read_csv(\"./data/Fake_del_hashtag.csv\")\n",
    "#real = pd.read_csv(\"./data/True_del_hashtag.csv\")\n",
    "\n",
    "#fake = pd.read_csv(\"./data/Fake_hashtags_removed.csv\")\n",
    "#real = pd.read_csv(\"./data/True_hashtags_removed.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                                               title  \\\n0  As U.S. budget fight looms, Republicans flip t...   \n1  U.S. military to accept transgender recruits o...   \n2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n3  FBI Russia probe helped by Australian diplomat...   \n4  Trump wants Postal Service to charge 'much mor...   \n\n                                                text       subject  \\\n0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n3  WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n4  SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n\n                 date  \n0  December 31, 2017   \n1  December 29, 2017   \n2  December 31, 2017   \n3  December 30, 2017   \n4  December 29, 2017   ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>text</th>\n      <th>subject</th>\n      <th>date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>As U.S. budget fight looms, Republicans flip t...</td>\n      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n      <td>politicsNews</td>\n      <td>December 31, 2017</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>U.S. military to accept transgender recruits o...</td>\n      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n      <td>politicsNews</td>\n      <td>December 29, 2017</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n      <td>politicsNews</td>\n      <td>December 31, 2017</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>FBI Russia probe helped by Australian diplomat...</td>\n      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n      <td>politicsNews</td>\n      <td>December 30, 2017</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Trump wants Postal Service to charge 'much mor...</td>\n      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n      <td>politicsNews</td>\n      <td>December 29, 2017</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cleaning\n",
    "\n",
    "This is part of the original code. As can be seen in the cell above, the real tweets are preceded by a publisher part. The fake ones don't have this, so it is removed altogether."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "#First Creating list of index that do not have publication part\n",
    "unknown_publishers = []\n",
    "for index,row in enumerate(real.text.values):\n",
    "    try:\n",
    "        record = row.split(\" -\", maxsplit=1)\n",
    "        #if no text part is present, following will give error\n",
    "        record[1]\n",
    "        #if len of piblication part is greater than 260\n",
    "        #following will give error, ensuring no text having \"-\" in between is counted\n",
    "        assert(len(record[0]) < 260)\n",
    "    except:\n",
    "        unknown_publishers.append(index)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "3488     The White House on Wednesday disclosed a group...\n4358     Neil Gorsuch, President Donald Trump’s appoint...\n4465     WASHINGTON The clock began running out this we...\n5784     Federal appeals court judge Neil Gorsuch, the ...\n6660     Republican members of Congress are complaining...\n6823     Over the course of the U.S. presidential campa...\n7922     After going through a week reminiscent of Napo...\n8194     The following timeline charts the origin and s...\n8195     Global health officials are racing to better u...\n8247     U.S. President Barack Obama visited a street m...\n8465     ALGONAC, MICH.—Parker Fox drifted out of the D...\n8481     Global health officials are racing to better u...\n8482     The following timeline charts the origin and s...\n8505     Global health officials are racing to better u...\n8506     The following timeline charts the origin and s...\n8771     In a speech weighted with America’s complicate...\n8970                                                      \n9008     The following timeline charts the origin and s...\n9009     Global health officials are racing to better u...\n9307     It’s the near future, and North Korea’s regime...\n9618     GOP leaders have unleashed a stunning level of...\n9737     Caitlyn Jenner posted a video on Wednesday (Ap...\n10479    The Democratic and Republican nominees for the...\nName: text, dtype: object"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Thus we have list of indices where publisher is not mentioned\n",
    "#lets check\n",
    "real.iloc[unknown_publishers].text\n",
    "#true, they do not have text like \"WASHINGTON (Reuters)\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "title      Graphic: Supreme Court roundup\ntext                                     \nsubject                      politicsNews\ndate                       June 16, 2016 \nName: 8970, dtype: object"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real.iloc[8970]\n",
    "#yep empty\n",
    "#will remove this soon"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "#Seperating Publication info, from actual text\n",
    "publisher = []\n",
    "tmp_text = []\n",
    "for index,row in enumerate(real.text.values):\n",
    "    if index in unknown_publishers:\n",
    "        #Add unknown of publisher not mentioned\n",
    "        tmp_text.append(row)\n",
    "\n",
    "        publisher.append(\"Unknown\")\n",
    "        continue\n",
    "    record = row.split(\" -\", maxsplit=1)\n",
    "    publisher.append(record[0])\n",
    "    tmp_text.append(record[1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "#Replace existing text column with new text\n",
    "#add seperate column for publication info\n",
    "real[\"publisher\"] = publisher\n",
    "real[\"text\"] = tmp_text\n",
    "\n",
    "del publisher, tmp_text, record, unknown_publishers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "                                               title  \\\n0  As U.S. budget fight looms, Republicans flip t...   \n1  U.S. military to accept transgender recruits o...   \n2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n3  FBI Russia probe helped by Australian diplomat...   \n4  Trump wants Postal Service to charge 'much mor...   \n\n                                                text       subject  \\\n0   The head of a conservative Republican faction...  politicsNews   \n1   Transgender people will be allowed for the fi...  politicsNews   \n2   The special counsel investigation of links be...  politicsNews   \n3   Trump campaign adviser George Papadopoulos to...  politicsNews   \n4   President Donald Trump called on the U.S. Pos...  politicsNews   \n\n                 date                     publisher  \n0  December 31, 2017           WASHINGTON (Reuters)  \n1  December 29, 2017           WASHINGTON (Reuters)  \n2  December 31, 2017           WASHINGTON (Reuters)  \n3  December 30, 2017           WASHINGTON (Reuters)  \n4  December 29, 2017   SEATTLE/WASHINGTON (Reuters)  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>text</th>\n      <th>subject</th>\n      <th>date</th>\n      <th>publisher</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>As U.S. budget fight looms, Republicans flip t...</td>\n      <td>The head of a conservative Republican faction...</td>\n      <td>politicsNews</td>\n      <td>December 31, 2017</td>\n      <td>WASHINGTON (Reuters)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>U.S. military to accept transgender recruits o...</td>\n      <td>Transgender people will be allowed for the fi...</td>\n      <td>politicsNews</td>\n      <td>December 29, 2017</td>\n      <td>WASHINGTON (Reuters)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n      <td>The special counsel investigation of links be...</td>\n      <td>politicsNews</td>\n      <td>December 31, 2017</td>\n      <td>WASHINGTON (Reuters)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>FBI Russia probe helped by Australian diplomat...</td>\n      <td>Trump campaign adviser George Papadopoulos to...</td>\n      <td>politicsNews</td>\n      <td>December 30, 2017</td>\n      <td>WASHINGTON (Reuters)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Trump wants Postal Service to charge 'much mor...</td>\n      <td>President Donald Trump called on the U.S. Pos...</td>\n      <td>politicsNews</td>\n      <td>December 29, 2017</td>\n      <td>SEATTLE/WASHINGTON (Reuters)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The next cleaning task is to get rid of empty texts"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "[8970]"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for rows with empty text like row:8970\n",
    "[index for index,text in enumerate(real.text.values) if str(text).strip() == '']\n",
    "#seems only one :)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "#dropping this record\n",
    "real = real.drop(8970, axis=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of empty rows: 630\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                   title text    subject  \\\n21816  BALTIMORE BURNS: MARYLAND GOVERNOR BRINGS IN N...       left-news   \n21826  FULL VIDEO: THE BLOCKBUSTER INVESTIGATION INTO...       left-news   \n21827  (VIDEO) HILLARY CLINTON: RELIGIOUS BELIEFS MUS...       left-news   \n21857  (VIDEO)ICE PROTECTING OBAMA: WON’T RELEASE NAM...       left-news   \n21873  (VIDEO) HYSTERICAL SNL TAKE ON HILLARY’S ANNOU...       left-news   \n\n               date  \n21816  Apr 27, 2015  \n21826  Apr 25, 2015  \n21827  Apr 25, 2015  \n21857  Apr 14, 2015  \n21873  Apr 12, 2015  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>text</th>\n      <th>subject</th>\n      <th>date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>21816</th>\n      <td>BALTIMORE BURNS: MARYLAND GOVERNOR BRINGS IN N...</td>\n      <td></td>\n      <td>left-news</td>\n      <td>Apr 27, 2015</td>\n    </tr>\n    <tr>\n      <th>21826</th>\n      <td>FULL VIDEO: THE BLOCKBUSTER INVESTIGATION INTO...</td>\n      <td></td>\n      <td>left-news</td>\n      <td>Apr 25, 2015</td>\n    </tr>\n    <tr>\n      <th>21827</th>\n      <td>(VIDEO) HILLARY CLINTON: RELIGIOUS BELIEFS MUS...</td>\n      <td></td>\n      <td>left-news</td>\n      <td>Apr 25, 2015</td>\n    </tr>\n    <tr>\n      <th>21857</th>\n      <td>(VIDEO)ICE PROTECTING OBAMA: WON’T RELEASE NAM...</td>\n      <td></td>\n      <td>left-news</td>\n      <td>Apr 14, 2015</td>\n    </tr>\n    <tr>\n      <th>21873</th>\n      <td>(VIDEO) HYSTERICAL SNL TAKE ON HILLARY’S ANNOU...</td>\n      <td></td>\n      <td>left-news</td>\n      <td>Apr 12, 2015</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for the same in fake news\n",
    "empty_fake_index = [index for index,text in enumerate(fake.text.values) if str(text).strip() == '']\n",
    "print(f\"No of empty rows: {len(empty_fake_index)}\")\n",
    "fake.iloc[empty_fake_index].tail()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Records:\t21416\n",
      "politicsNews:\t11271\n",
      "worldnews:\t10145\n"
     ]
    }
   ],
   "source": [
    "#Getting Total Rows\n",
    "print(f\"Total Records:\\t{real.shape[0]}\")\n",
    "\n",
    "#Counting by Subjects\n",
    "for key,count in real.subject.value_counts().items():\n",
    "  print(f\"{key}:\\t{count}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preparation\n",
    "\n",
    "This is also part of the original code. It adds the labels, removes columns that are not used and prepares the dataset to be tokenized by Word2Vec"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Adding class Information\n",
    "real[\"class\"] = 1\n",
    "fake[\"class\"] = 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "#Combining Title and Text\n",
    "real[\"text\"] = real[\"title\"] + \" \" + real[\"text\"]\n",
    "fake[\"text\"] = fake[\"title\"] + \" \" + fake[\"text\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Subject is diffrent for real and fake thus dropping it\n",
    "# Aldo dropping Date, title and Publication Info of real\n",
    "real = real.drop([\"subject\", \"date\",\"title\",  \"publisher\"], axis=1)\n",
    "fake = fake.drop([\"subject\", \"date\", \"title\"], axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "#Combining both into new dataframe\n",
    "data = pd.concat([real, fake], ignore_index=True)\n",
    "del real, fake"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tokenize\n",
    "\n",
    "This is also part of the original code. This piece downloads vocabs for word2vec and feeds the individual sentences to word2vec"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dagma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dagma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "y = data[\"class\"].values\n",
    "#Converting X to format acceptable by gensim, removing annd punctuation stopwords in the process\n",
    "X = []\n",
    "stop_words = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "for par in data[\"text\"].values:\n",
    "    tmp = []\n",
    "    sentences = nltk.sent_tokenize(par)\n",
    "    for sent in sentences:\n",
    "        sent = sent.lower()\n",
    "        tokens = tokenizer.tokenize(sent)\n",
    "        filtered_words = [w.strip() for w in tokens if w not in stop_words and len(w) > 1]\n",
    "        tmp.extend(filtered_words)\n",
    "    X.append(tmp)\n",
    "\n",
    "del data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "import gensim"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "#Dimension of vectors we are generating\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "#Creating Word Vectors by Word2Vec Method (takes time...)\n",
    "w2v_model = gensim.models.Word2Vec(sentences=X, vector_size=EMBEDDING_DIM, window=5, min_count=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "122248"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vocab size\n",
    "len(w2v_model.wv.index_to_key)\n",
    "\n",
    "#We have now represented each of 122248 words by a 100dim vector."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "array([-0.01828363,  0.08742693,  0.0468708 , -0.03075433, -0.02054556,\n       -0.06074217,  0.11057762,  0.14916635, -0.03113902, -0.12705462,\n       -0.04086402,  0.010533  ,  0.0051034 , -0.04257664, -0.00053019,\n       -0.10215867, -0.03474014, -0.03577403,  0.04852349, -0.01144259,\n       -0.02375835,  0.06665067, -0.06148059, -0.0686955 , -0.0184469 ,\n       -0.0018119 , -0.04965044,  0.05046534, -0.05091721, -0.00160264,\n       -0.04772158, -0.05259814, -0.08014508, -0.02204122, -0.00225765,\n        0.05476005,  0.00570274,  0.03177148, -0.0117913 , -0.0520692 ,\n        0.03790703,  0.00729636, -0.07788165,  0.02203698,  0.05124233,\n        0.01721014, -0.03273949,  0.02172087,  0.02875224,  0.00253236,\n        0.01323481, -0.07240389, -0.01898581, -0.02162234,  0.02179711,\n        0.02327675,  0.01442333, -0.03301975, -0.03293015,  0.07374023,\n        0.01240478,  0.03541964, -0.01097257,  0.03573813, -0.00404664,\n        0.04617042,  0.02074417, -0.01066715, -0.05825996,  0.02541732,\n       -0.01340029,  0.01486796,  0.00079921, -0.01026479,  0.04383531,\n        0.02300476, -0.01434578, -0.00997848, -0.06063848, -0.03614414,\n        0.00375434,  0.03101467, -0.01464235,  0.09226625, -0.01069412,\n        0.07105431,  0.05616019,  0.0336998 ,  0.03646548,  0.01650965,\n       -0.00116059,  0.05092232, -0.02766451,  0.01177088,  0.05438715,\n        0.04343893,  0.03106764, -0.04681691, -0.01914611,  0.04189465],\n      dtype=float32)"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#see a sample vector for random word, lets say Corona\n",
    "w2v_model.wv[\"corona\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# Tokenizing Text -> Repsesenting each word by a number\n",
    "# Mapping of orginal word to number is preserved in word_index property of tokenizer\n",
    "\n",
    "#Tokenized applies basic processing like changing it yo lower case, explicitely setting that as False\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X)\n",
    "\n",
    "X = tokenizer.texts_to_sequences(X)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "[389, 395, 10495, 54, 5509, 1286, 4840, 315, 205, 16]"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets check the first 10 words of first news\n",
    "#every word has been represented with a number\n",
    "X[0][:10]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trump -> 1\n",
      "said -> 2\n",
      "president -> 3\n",
      "would -> 4\n",
      "people -> 5\n",
      "one -> 6\n",
      "state -> 7\n",
      "new -> 8\n",
      "obama -> 9\n",
      "also -> 10\n"
     ]
    }
   ],
   "source": [
    "#Lets check few word to numerical replesentation\n",
    "#Mapping is preserved in dictionary -> word_index property of instance\n",
    "word_index = tokenizer.word_index\n",
    "for word, num in word_index.items():\n",
    "    print(f\"{word} -> {num}\")\n",
    "    if num == 10:\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For determining size of input...\n",
    "\n",
    "# Making histogram for no of words in news shows that most news article are under 700 words.\n",
    "# Lets keep each news small and truncate all news to 700 while tokenizing\n",
    "plt.hist([len(x) for x in X], bins=500, color = \"skyblue\", ec=\"skyblue\")\n",
    "plt.show()\n",
    "\n",
    "# Its heavily skewed. There are news with 5000 words? Lets truncate these outliers :)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "43982"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nos = np.array([len(x) for x in X])\n",
    "len(nos[nos  < 700])\n",
    "# Out of 48k news, 44k have less than 700 words"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "#Lets keep all news to 700, add padding to news with less than 700 words and truncating long ones\n",
    "maxlen = 700\n",
    "\n",
    "#Making all news of size maxlen defined above\n",
    "X = pad_sequences(X, maxlen=maxlen)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "700"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all news has 700 words (in numerical form now). If they had less words, they have been padded with 0\n",
    "# 0 is not associated to any word, as mapping of words started from 1\n",
    "# 0 will also be used later, if unknows word is encountered in test set\n",
    "len(X[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "# Adding 1 because of reserved 0 index\n",
    "# Embedding Layer creates one more vector for \"UNKNOWN\" words, or padded words (0s). This Vector is filled with zeros.\n",
    "# Thus our vocab size inceeases by 1\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "# Function to create weight matrix from word2vec gensim model\n",
    "def get_weight_matrix(model, vocab):\n",
    "    # total vocabulary size plus 0 for unknown words\n",
    "    vocab_size = len(vocab) + 1\n",
    "    # define weight matrix dimensions with all 0\n",
    "    weight_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
    "    # step vocab, store vectors using the Tokenizer's integer mapping\n",
    "    for word, i in vocab.items():\n",
    "        weight_matrix[i] = model[word]\n",
    "    return weight_matrix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "#Getting embedding vectors from word2vec and usings it as weights of non-trainable keras embedding layer\n",
    "embedding_vectors = get_weight_matrix(w2v_model.wv, word_index)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Build the model\n",
    "\n",
    "We left the essence of the original code intact, but we split it into several functions, so that the train/test split can be done repeatedly with different seeds.\n",
    "We also created a loop around the actual training and eval. We do this to create a distribution, so we can later apply statistical tests on the results."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "#Defining Neural Network\n",
    "def build_model(emb_vectors, EMB_DIM, voc_size, length):\n",
    "    mod = Sequential()\n",
    "    #Non-trainable embeddidng layer\n",
    "    mod.add(Embedding(voc_size, output_dim=EMB_DIM, weights=[emb_vectors], input_length=length, trainable=False))\n",
    "    #LSTM\n",
    "    mod.add(LSTM(units=128))\n",
    "    mod.add(Dense(1, activation='sigmoid'))\n",
    "    mod.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "    return mod\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "#Train test split\n",
    "def split(X, y, seed):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=seed)\n",
    "    return X_train, X_test, y_train, y_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define a list to keep track of the results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "result = []"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And then create the sample (n=32)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing iteration 0\n",
      "WARNING:tensorflow:From C:\\Users\\dagma\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dagma\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/6\n",
      "WARNING:tensorflow:From C:\\Users\\dagma\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dagma\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "737/737 [==============================] - 365s 493ms/step - loss: 0.1305 - acc: 0.9516 - val_loss: 0.0875 - val_acc: 0.9686\n",
      "Epoch 2/6\n",
      "737/737 [==============================] - 333s 452ms/step - loss: 0.0648 - acc: 0.9782 - val_loss: 0.0530 - val_acc: 0.9826\n",
      "Epoch 3/6\n",
      "737/737 [==============================] - 319s 432ms/step - loss: 0.0415 - acc: 0.9860 - val_loss: 0.0415 - val_acc: 0.9863\n",
      "Epoch 4/6\n",
      "737/737 [==============================] - 316s 428ms/step - loss: 0.0371 - acc: 0.9868 - val_loss: 0.0366 - val_acc: 0.9883\n",
      "Epoch 5/6\n",
      "737/737 [==============================] - 327s 444ms/step - loss: 0.0257 - acc: 0.9914 - val_loss: 0.0986 - val_acc: 0.9630\n",
      "Epoch 6/6\n",
      "737/737 [==============================] - 313s 424ms/step - loss: 0.0363 - acc: 0.9877 - val_loss: 0.0377 - val_acc: 0.9865\n",
      "351/351 [==============================] - 51s 145ms/step\n",
      "Processing iteration 1\n",
      "Epoch 1/6\n",
      "737/737 [==============================] - 327s 441ms/step - loss: 0.1265 - acc: 0.9552 - val_loss: 0.1401 - val_acc: 0.9397\n",
      "Epoch 2/6\n",
      "737/737 [==============================] - 331s 449ms/step - loss: 0.0770 - acc: 0.9737 - val_loss: 0.1156 - val_acc: 0.9581\n",
      "Epoch 3/6\n",
      "737/737 [==============================] - 320s 435ms/step - loss: 0.0549 - acc: 0.9810 - val_loss: 0.0421 - val_acc: 0.9867\n",
      "Epoch 4/6\n",
      "737/737 [==============================] - 336s 456ms/step - loss: 0.0533 - acc: 0.9822 - val_loss: 0.0527 - val_acc: 0.9832\n",
      "Epoch 5/6\n",
      "737/737 [==============================] - 341s 463ms/step - loss: 0.0285 - acc: 0.9901 - val_loss: 0.0403 - val_acc: 0.9862\n",
      "Epoch 6/6\n",
      "737/737 [==============================] - 365s 496ms/step - loss: 0.0155 - acc: 0.9945 - val_loss: 0.0291 - val_acc: 0.9905\n",
      "351/351 [==============================] - 53s 151ms/step\n",
      "Processing iteration 2\n",
      "Epoch 1/6\n",
      "737/737 [==============================] - 350s 470ms/step - loss: 0.1248 - acc: 0.9542 - val_loss: 0.2197 - val_acc: 0.9080\n",
      "Epoch 2/6\n",
      "737/737 [==============================] - 323s 438ms/step - loss: 0.0907 - acc: 0.9661 - val_loss: 0.0836 - val_acc: 0.9711\n",
      "Epoch 3/6\n",
      "737/737 [==============================] - 320s 434ms/step - loss: 0.0441 - acc: 0.9854 - val_loss: 0.0534 - val_acc: 0.9836\n",
      "Epoch 4/6\n",
      "737/737 [==============================] - 319s 433ms/step - loss: 0.0386 - acc: 0.9868 - val_loss: 0.0388 - val_acc: 0.9862\n",
      "Epoch 5/6\n",
      "737/737 [==============================] - 314s 426ms/step - loss: 0.0361 - acc: 0.9874 - val_loss: 0.0380 - val_acc: 0.9879\n",
      "Epoch 6/6\n",
      "737/737 [==============================] - 314s 426ms/step - loss: 0.0188 - acc: 0.9937 - val_loss: 0.0272 - val_acc: 0.9913\n",
      "351/351 [==============================] - 54s 153ms/step\n",
      "Processing iteration 3\n",
      "Epoch 1/6\n",
      "737/737 [==============================] - 315s 425ms/step - loss: 0.1272 - acc: 0.9557 - val_loss: 0.0976 - val_acc: 0.9660\n",
      "Epoch 2/6\n",
      "737/737 [==============================] - 315s 427ms/step - loss: 0.0646 - acc: 0.9764 - val_loss: 0.0427 - val_acc: 0.9856\n",
      "Epoch 3/6\n",
      "737/737 [==============================] - 316s 429ms/step - loss: 0.0435 - acc: 0.9854 - val_loss: 0.0771 - val_acc: 0.9735\n",
      "Epoch 4/6\n",
      "737/737 [==============================] - 315s 427ms/step - loss: 0.0564 - acc: 0.9816 - val_loss: 0.1354 - val_acc: 0.9446\n",
      "Epoch 5/6\n",
      "737/737 [==============================] - 327s 444ms/step - loss: 0.0511 - acc: 0.9824 - val_loss: 0.0528 - val_acc: 0.9827\n",
      "Epoch 6/6\n",
      "737/737 [==============================] - 322s 437ms/step - loss: 0.0205 - acc: 0.9932 - val_loss: 0.0376 - val_acc: 0.9886\n",
      "351/351 [==============================] - 54s 153ms/step\n",
      "Processing iteration 4\n",
      "Epoch 1/6\n",
      "737/737 [==============================] - 322s 435ms/step - loss: 0.1453 - acc: 0.9458 - val_loss: 0.1876 - val_acc: 0.9368\n",
      "Epoch 2/6\n",
      "737/737 [==============================] - 322s 437ms/step - loss: 0.0755 - acc: 0.9746 - val_loss: 0.0514 - val_acc: 0.9851\n",
      "Epoch 3/6\n",
      "737/737 [==============================] - 317s 431ms/step - loss: 0.0417 - acc: 0.9863 - val_loss: 0.0381 - val_acc: 0.9885\n",
      "Epoch 4/6\n",
      "737/737 [==============================] - 330s 448ms/step - loss: 0.0307 - acc: 0.9893 - val_loss: 0.0294 - val_acc: 0.9906\n",
      "Epoch 5/6\n",
      "737/737 [==============================] - 335s 454ms/step - loss: 0.0186 - acc: 0.9940 - val_loss: 0.0324 - val_acc: 0.9897\n",
      "Epoch 6/6\n",
      "737/737 [==============================] - 337s 457ms/step - loss: 0.0166 - acc: 0.9943 - val_loss: 0.0374 - val_acc: 0.9884\n",
      "351/351 [==============================] - 62s 174ms/step\n",
      "Processing iteration 5\n",
      "Epoch 1/6\n",
      "737/737 [==============================] - 333s 448ms/step - loss: 0.1292 - acc: 0.9541 - val_loss: 0.0796 - val_acc: 0.9744\n",
      "Epoch 2/6\n",
      "737/737 [==============================] - 335s 455ms/step - loss: 0.1244 - acc: 0.9536 - val_loss: 0.1002 - val_acc: 0.9667\n",
      "Epoch 3/6\n",
      "737/737 [==============================] - 330s 448ms/step - loss: 0.0808 - acc: 0.9720 - val_loss: 0.1055 - val_acc: 0.9648\n",
      "Epoch 4/6\n",
      "737/737 [==============================] - 332s 450ms/step - loss: 0.0512 - acc: 0.9821 - val_loss: 0.0433 - val_acc: 0.9855\n",
      "Epoch 5/6\n",
      "737/737 [==============================] - 330s 448ms/step - loss: 0.0356 - acc: 0.9877 - val_loss: 0.0447 - val_acc: 0.9857\n",
      "Epoch 6/6\n",
      "737/737 [==============================] - 327s 444ms/step - loss: 0.0362 - acc: 0.9878 - val_loss: 0.0391 - val_acc: 0.9874\n",
      "351/351 [==============================] - 53s 151ms/step\n",
      "Processing iteration 6\n",
      "Epoch 1/6\n",
      "737/737 [==============================] - 359s 485ms/step - loss: 0.1264 - acc: 0.9541 - val_loss: 0.0812 - val_acc: 0.9723\n",
      "Epoch 2/6\n",
      "737/737 [==============================] - 368s 499ms/step - loss: 0.0750 - acc: 0.9753 - val_loss: 0.0557 - val_acc: 0.9828\n",
      "Epoch 3/6\n",
      "737/737 [==============================] - 364s 493ms/step - loss: 0.0756 - acc: 0.9744 - val_loss: 0.0818 - val_acc: 0.9730\n",
      "Epoch 4/6\n",
      "737/737 [==============================] - 361s 490ms/step - loss: 0.0489 - acc: 0.9838 - val_loss: 0.0669 - val_acc: 0.9775\n",
      "Epoch 5/6\n",
      "737/737 [==============================] - 357s 485ms/step - loss: 0.0298 - acc: 0.9905 - val_loss: 0.0545 - val_acc: 0.9835\n",
      "Epoch 6/6\n",
      "737/737 [==============================] - 359s 487ms/step - loss: 0.0289 - acc: 0.9905 - val_loss: 0.0407 - val_acc: 0.9859\n",
      "351/351 [==============================] - 61s 174ms/step\n",
      "Processing iteration 7\n",
      "Epoch 1/6\n",
      "737/737 [==============================] - 357s 481ms/step - loss: 0.1203 - acc: 0.9570 - val_loss: 0.0811 - val_acc: 0.9719\n",
      "Epoch 2/6\n",
      "737/737 [==============================] - 353s 479ms/step - loss: 0.0688 - acc: 0.9766 - val_loss: 0.0602 - val_acc: 0.9800\n",
      "Epoch 3/6\n",
      "737/737 [==============================] - 354s 480ms/step - loss: 0.0530 - acc: 0.9831 - val_loss: 0.0579 - val_acc: 0.9817\n",
      "Epoch 4/6\n",
      "737/737 [==============================] - 353s 479ms/step - loss: 0.0285 - acc: 0.9909 - val_loss: 0.0452 - val_acc: 0.9842\n",
      "Epoch 5/6\n",
      "737/737 [==============================] - 355s 481ms/step - loss: 0.0208 - acc: 0.9937 - val_loss: 0.0659 - val_acc: 0.9756\n",
      "Epoch 6/6\n",
      "737/737 [==============================] - 354s 481ms/step - loss: 0.0273 - acc: 0.9902 - val_loss: 0.0469 - val_acc: 0.9817\n",
      "351/351 [==============================] - 56s 160ms/step\n",
      "Processing iteration 8\n",
      "Epoch 1/6\n",
      "737/737 [==============================] - 334s 451ms/step - loss: 0.1279 - acc: 0.9543 - val_loss: 0.1485 - val_acc: 0.9523\n",
      "Epoch 2/6\n",
      "449/737 [=================>............] - ETA: 1:51 - loss: 0.0933 - acc: 0.9669"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_9240\\783394775.py\u001B[0m in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      3\u001B[0m     \u001B[0mX_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX_test\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_test\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msplit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn\u001B[0m\u001B[1;33m+\u001B[0m\u001B[1;36m24\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m     \u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbuild_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0membedding_vectors\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mEMBEDDING_DIM\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvocab_size\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmaxlen\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m     \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalidation_split\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0.3\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m6\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m     \u001B[1;31m#Prediction is in probability of news being real, so converting into classes\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m     \u001B[1;31m# Class 0 (Fake) if predicted prob < 0.5, else class 1 (Real)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m         \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     64\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 65\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     66\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     67\u001B[0m             \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1805\u001B[0m                         ):\n\u001B[0;32m   1806\u001B[0m                             \u001B[0mcallbacks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1807\u001B[1;33m                             \u001B[0mtmp_logs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1808\u001B[0m                             \u001B[1;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1809\u001B[0m                                 \u001B[0mcontext\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    149\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 150\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    151\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    152\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    830\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    831\u001B[0m       \u001B[1;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_jit_compile\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 832\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    833\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    834\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001B[0m in \u001B[0;36m_call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    866\u001B[0m       \u001B[1;31m# In this case we have created variables on the first call, so we run the\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    867\u001B[0m       \u001B[1;31m# defunned version which is guaranteed to never create variables.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 868\u001B[1;33m       return tracing_compilation.call_function(\n\u001B[0m\u001B[0;32m    869\u001B[0m           \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_no_variable_creation_config\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    870\u001B[0m       )\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py\u001B[0m in \u001B[0;36mcall_function\u001B[1;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[0;32m    137\u001B[0m   \u001B[0mbound_args\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfunction\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfunction_type\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbind\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    138\u001B[0m   \u001B[0mflat_inputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfunction\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfunction_type\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0munpack_inputs\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbound_args\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 139\u001B[1;33m   return function._call_flat(  # pylint: disable=protected-access\n\u001B[0m\u001B[0;32m    140\u001B[0m       \u001B[0mflat_inputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcaptured_inputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mfunction\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcaptured_inputs\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    141\u001B[0m   )\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[1;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[0;32m   1321\u001B[0m         and executing_eagerly):\n\u001B[0;32m   1322\u001B[0m       \u001B[1;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1323\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_inference_function\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcall_preflattened\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1324\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001B[0;32m   1325\u001B[0m         \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py\u001B[0m in \u001B[0;36mcall_preflattened\u001B[1;34m(self, args)\u001B[0m\n\u001B[0;32m    214\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0mcall_preflattened\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mSequence\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mAny\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    215\u001B[0m     \u001B[1;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 216\u001B[1;33m     \u001B[0mflat_outputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcall_flat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    217\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfunction_type\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpack_output\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mflat_outputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    218\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py\u001B[0m in \u001B[0;36mcall_flat\u001B[1;34m(self, *args)\u001B[0m\n\u001B[0;32m    249\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mrecord\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstop_recording\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    250\u001B[0m           \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_bound_context\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexecuting_eagerly\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 251\u001B[1;33m             outputs = self._bound_context.call_function(\n\u001B[0m\u001B[0;32m    252\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    253\u001B[0m                 \u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\context.py\u001B[0m in \u001B[0;36mcall_function\u001B[1;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[0;32m   1484\u001B[0m     \u001B[0mcancellation_context\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcancellation\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcontext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1485\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mcancellation_context\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1486\u001B[1;33m       outputs = execute.execute(\n\u001B[0m\u001B[0;32m   1487\u001B[0m           \u001B[0mname\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdecode\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"utf-8\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1488\u001B[0m           \u001B[0mnum_outputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mnum_outputs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     51\u001B[0m   \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     52\u001B[0m     \u001B[0mctx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 53\u001B[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0m\u001B[0;32m     54\u001B[0m                                         inputs, attrs, num_outputs)\n\u001B[0;32m     55\u001B[0m   \u001B[1;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# DO NOT RUN THIS CELL unless you have patience.\n",
    "# Each epoch can take up to 5 to 10 minutes, and each iteration has 6 epochs\n",
    "# Meaning: creating a sample of 32 datapoints can take between 16 and 32 hours.\n",
    "# LSTMs are slow. They cannot handle parallelization because of their innate sequential nature.\n",
    "\n",
    "for n in range(32):\n",
    "    print(\"Processing iteration \" + str(n))\n",
    "    X_train, X_test, y_train, y_test = split(X, y, n+24)\n",
    "    model = build_model(embedding_vectors, EMBEDDING_DIM, vocab_size, maxlen)\n",
    "    model.fit(X_train, y_train, validation_split=0.3, epochs=6)\n",
    "    #Prediction is in probability of news being real, so converting into classes\n",
    "    # Class 0 (Fake) if predicted prob < 0.5, else class 1 (Real)\n",
    "    y_pred = (model.predict(X_test) >= 0.5).astype(\"int\")\n",
    "    # add y_test and y_pred to result for later use\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    result.append((acc, prec, rec, f1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And then save the result. Notebook fake_news_results takes these as inputs."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "# save the result\n",
    "column_names = ['Accuracy', 'Precision', 'Recall', 'F1']\n",
    "df = pd.DataFrame(result, columns=column_names)\n",
    "df.to_csv('./result.csv', index=False, header=True)\n",
    "#df.to_csv('./result_del_hashtag.csv', index=False, header=True)\n",
    "#df.to_csv('./result_hashtags_removed.csv', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "del model\n",
    "del embedding_vectors"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
